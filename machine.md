# machine

{% embed url="https://mp.weixin.qq.com/s/xUaFSdIMRI11agwwUUK2oA" %}

{% embed url="http://gnetna.com/books/%E6%A6%82%E7%8E%87%E8%AE%BA/" %}

python [https://www.bilibili.com/video/av52080698/?p=4](https://www.bilibili.com/video/av52080698/?p=4)



{% embed url="https://github.com/Jack-Cherish/PythonPark" %}

[https://github.com/adamian98/pulse](https://github.com/adamian98/pulse) [http://pulse.cs.duke.edu/](http://pulse.cs.duke.edu/) [https://arxiv.org/pdf/2003.03808.pdf](https://arxiv.org/pdf/2003.03808.pdf)

MIT linear algebra by Gilbert Strang:

{% embed url="https://www.youtube.com/playlist?list=PLUl4u3cNGP61iQEFiWLE21EJCxwmWvvek" %}

{% embed url="https://cuijiahua.com/blog/ml/%0Ahttps://github.com/yunjey/pytorch-tutorial%0A%0Ahttps://github.com/Jack-Cherish/Deep-Learning" %}



```
Deep Learning from Scratch with PyTorch Tutorial | SciPy 2020 | Dhavide Aruliah, Hugo Bowne-Anderson https://www.youtube.com/watch?v=CW8hTe21LPg https://github.com/hugobowne/deep-learning-from-scratch-pytorch.git

https://scikit-learn.org/stable/modules/cross_validation.html

https://github.com/chendaniely/scipy-2020-pandas

weight times x: https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html

https://sebastianraschka.com/faq/docs/backprop-arbitrary.html https://sebastianraschka.com/

Deep Learning from Scratch with PyTorch Tutorial | SciPy 2020 | Dhavide Aruliah, Hugo Bowne-Anderson https://youtu.be/CW8hTe21LPg?t=10602 https://github.com/hugobowne/deep-learning-from-scratch-pytorch/blob/master/notebooks/2-Instructor-deep-learning-from-scratch-pytorch.ipynb http://neuralnetworksanddeeplearning.com/ https://www.scipy2020.scipy.org/tutorial-information

taiwan machine learning class-
https://www.youtube.com/watch?v=ripP9uMPpfE

neural networks

AI roadmap https://github.com/apachecn/ai-roadmap/tree/master/v1.0
deep learning book online - need code implementation

https://github.com/MichalDanielDobrzanski/DeepLearningPython35/blob/master/network.py
https://github.com/antonvladyka/neuralnetworksanddeeplearning.com.pdf
zip=pair-up element-wise
on page 100

CNN - vision; 3 layers: convolution, pooling, full connection
RNN - sequence analysis/NLP, keras

1. 斯坦福CS231N计算机视觉作业讲解
2 layer net has both forward and backward gradient calc
https://github.com/L1aoXingyu/cs231n-assignment-solution/blob/master/assignment1/two_layer_net.ipynb
https://www.bilibili.com/video/BV1t4411U78z?p=6 batch normalization (reached)
https://github.com/L1aoXingyu/cs231n-assignment-solution/blob/master/assignment2/cs231n/layers.py has batchnorm_backward
and batchnorm_forward; batch norm vs layer norm; batchnorm_backward_alt is 1.4 times faster than batchnorm_backward;
layernorm_forward() and layernorm_backward() implemented

https://github.com/L1aoXingyu/cs231n-assignment-solution/blob/master/assignment2/cs231n/classifiers/fc_net.py
is about dropout for fc_net.py
Fully-connected nets with Dropout
CNN

2. andrew ng machine learning assignment solutions python; exercise 4 has NN for both forward and backpropagation
video - https://www.bilibili.com/video/BV124411A75S?p=6
code -
only feedforward - https://github.com/Akpandita/Andrew-NG-ML-Python-Solutions/blob/master/Exercise3/exercise3.ipynb
feedforward and backpropagation https://github.com/suraggupta/coursera-machine-learning-solutions-python/blob/master/Exercise4/exercise4.ipynb

https://github.com/shamiul94/Machine-Learning-Coursera-Assignments-Solution/blob/master/Assignment-4/Given-Materials-Python/exercise4.ipynb

https://github.com/DantesHub/my-coursera-machine-learning-solutions-python/blob/master/Exercise4/exercise4.ipynb

3. tensorflow DFN model:
https://github.com/apachecn/misc-docs-zh/blob/master/docs/python-programming-net/python-programming-net-ml/4.md
stock price forecasting:
https://github.com/apachecn/misc-docs-zh/blob/master/docs/python-programming-net/python-programming-net-ml/1.md

source is at pythonprogramming.net, the NN started at:

https://pythonprogramming.net/tensorflow-deep-neural-network-machine-learning-tutorial/

and ended at:

https://pythonprogramming.net/data-size-example-tensorflow-deep-learning-tutorial/?completed=/train-test-tensorflow-deep-learning-tutorial/

https://github.com/apachecn/misc-docs-zh/blob/master/docs/first_contact_with_tensorFlow/4.md

弱鸡才用tensorflow，强者一个numpy就够：从零开始神经网络第一期
https://www.bilibili.com/video/BV1m4411x7KU/?spm_id_from=333.788.videocard.7
https://peigizhu.gitee.io/2020/07/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/
https://www.bilibili.com/video/BV1z4411e7WE
https://gitee.com/peigizhu/NeuralNetworks/blob/master/DeeplearningPro.py

知识体系、算法题、教程、面经，这是一份超赞的AI资源列
https://cloud.tencent.com/developer/article/1472683

https://www.bilibili.com/video/BV1t4411U78z?p=1
code https://github.com/L1aoXingyu/cs231n-assignment-solution/blob/master/assignment1/softmax.ipynb
https://www.bilibili.com/video/BV1t4411U78z?p=4
https://nndl.github.io/ 复旦 good book
https://github.com/nndl/exercise/blob/master/chap2_linear_regression/linear_regression-tf2.0.ipynb

https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9
https://github.com/jldbc/numpy_neural_net/blob/master/four_layer_network.py

not sure https://github.com/JGuymont/numpy-multilayer-perceptron/blob/master/neural_network/mlp.py
https://github.com/MingchaoZhu/DeepLearning/blob/master/code/chapter6.py#L52
http://deeplearning.net/tutorial/code/mlp.py

chap 6 deep feedforward networks = feedforward neural networks = multi-layer perceptrons (MLP)
math/linear algebra/probability/statistics are so complicated now only computer can understand them.
no programming no math; math should be done by computer, not human!
bagging=bootstrap aggregating
ROC=receiver operating characteristic curve
AUC = area under curve

3blue1brown, aops, brilliant.org/3b1b
https://www.youtube.com/watch?v=XkY2DOUCWMU&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=4
natural pattern - pattern recognition
addition, multiplication, composition = 3 ways to get a new function; sum rule, product rule, chain rule
taylor series = radius of convergence; ln(x) diverges; e^x converges
visual=graph=geometry; number=algebra=literal=language
fourier transform=everything is rotations https://www.youtube.com/watch?v=r6sGWTCMz2k

https://brilliant.org/principles/
The mind is not a vessel to be filled, but a fire to be kindled.”
— Plutarch
passion - Effective math and science learning…
Excites.
The greatest challenges to education are disinterest and apathy.

Cultivates curiosity.
Questions and storytelling that cultivate natural curiosity are better than the threat of a test.

Is active.
Effective learning is active, not passive. Watching a video is not enough.

Is applicable.
Use it or lose it: it is essential to apply what you're learning as you learn it.

Is community driven.
A community that challenges and inspires you is invaluable.

Doesn't discriminate.
Your age, country, and gender don't determine what you are capable of learning.

Allows for failure.
The best learners allow themselves to make many mistakes along their journey.

Sparks questions.
The culmination of a great education isn't knowing all the answers — it's knowing what to ask.

Brought to you by you: http://3b1b.co/alt-calc-thanks
And by Brilliant: https://brilliant.org/3b1b
Home page: https://www.3blue1brown.com
Essence of calculus series:
http://3b1b.co/calculus
Really nice applet made based on this video by Reddit user Larconneur:
https://www.geogebra.org/m/rftwacsy
Various social media stuffs:
Website: https://www.3blue1brown.com
Twitter: https://twitter.com/3blue1brown
Patreon: https://patreon.com/3blue1brown
Facebook: https://www.facebook.com/3blue1brown
Reddit: https://www.reddit.com/r/3blue1brown
An animated introduction to the Fourier Transform.
Home page: https://www.3blue1brown.com/
Brought to you by you: http://3b1b.co/fourier-thanks

Follow-on video about the uncertainty principle: https://youtu.be/MBnnXbOM5S4

Interactive made by a viewer inspired by this video:
https://prajwalsouza.github.io/Experiments/Fourier-Transform-Visualization.html
https://prajwalsouza.github.io/Experi...

Also, take a look at this Jupyter notebook implementing this idea in a way you can play with:
https://github.com/thatSaneKid/fourie...
https://github.com/thatSaneKid/fourier/blob/master/Fourier%20Transform%20-%20A%20Visual%20Introduction.ipynb

------------------
Animations largely made using manim, a scrappy open-source python library.  https://github.com/3b1b/manim


https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf 2012
http://www.cs.toronto.edu/~bonner/courses/2018s/csc338/matrix_cookbook.pdf 2006
https://www.ics.uci.edu/~welling/teaching/KernelsICS273B/MatrixCookBook.pdf 2005

读Ian Goodfellow 深度学习教科书：图解版
https://www.bilibili.com/video/BV1uW411g7im?p=10
https://www.bilibili.com/video/BV1uW411g7im/?spm_id_from=333.788.videocard.6

《深度学习》花书啃书指导！大佬级up主：同济子豪兄出任导师哦~【完结】
https://www.bilibili.com/video/BV1kE4119726?p=6
https://github.com/exacity/deeplearningbook-chinese
https://github.com/MingchaoZhu/DeepLearning
https://zhuanlan.zhihu.com/p/38431213 深度学习花书读书笔记目录

https://www.asimovinstitute.org/neural-network-zoo/
https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464
https://www.deeplearningbook.org/

google embedding projector
https://www.naftaliharris.com/blog/visualizing-k-means-clustering/
https://stanford.edu/class/engr108/visualizations/kmeans/kmeans.htmld

深度之眼官方账号【0基础小白学习公开课/书籍进阶之路】
1、机器学习入门：
吴恩达《机器学习》公开课，作业讲解： BV124411A75S
2、机器学习进阶：
周志华《机器学习》西瓜书，啃书指导： BV1wx411o7CK
李航《统计学习方法》，啃书指导：BV1i4411G7Xv
《机器学习实战》，啃书指导：BV1y4411g7ia
3、深度学习入门：
神经网络基础 :http://suo.im/69ytXN
4、深度学习框架学习：
PyTorch框架实战 http://suo.im/5UAGgp
TensorFlow2.0框架班:http://suo.im/5UAGv5
5、深度学习进阶：
《深度学习》花书，啃书指导： BV1kE4119726
6、深度学习应用：
斯坦福李飞飞《计算机视觉》CS231N公开课作业讲解 BV1t4411U78z
斯坦福CS224N《自然语言处理》公开课作业讲解 BV1X4411977R
7、求职面试：
《百面机器学习》葫芦书 啃书指导: BV1gt41157eq
求职分享区 BV1Vt411F7NW
经验分享区 BV1J4411B72T
（ 备注:获取以上电子书, 加我微信:  deepshare1010  ）
P1
深度学习花书-开场白
01:44
P2
花书全书内容概览
04:21
P3
花书参考资料盘点
03:43
P4
第一章-深度学习导论
35:59
P5
第二章-线性代数
22:31
P6
第三章-概率论和信息论
21:24
P7
第四章-数值计算
22:51
P8
第五章-机器学习基础
33:48
P9
第六章 深度前馈神经网络
31:46
P10
第七章 深度学习的正则化
31:01
P11
第八章 深度学习的训练优化
36:45
P12
第九章 卷积神经网络
23:02
P13
第十章 序列模型-循环神经网络和递归神经网络
22:11
P14
第十一章-训练调优实战方法
34:50
P15
第十二章-深度学习应用
28:17
P16
第十三章-线性因子模型
11:47
P17
第十四章-自动编码器
19:44
P18
第十五章-表示学习
28:39
P19
第十六章-结构化概率模型
16:05
P20
第十七章-蒙特卡洛方法
21:41
P21
第十八章-配分函数
15:33
P22
第十九章-近似推断
17:54
P23
第二十章-深度生成模型-生成模型综述
26:00
P24
第二十章-深度生成模型-生成对抗网络GAN
18:42


git filter-branch -f --index-filter 'git rm --cached --ignore-unmatch file'

洛谷 P1551. 并查集板子（亲戚）题解
https://www.acwing.com/file_system/file/content/whole/index/content/1415047/

【一起啃书】机器学习西瓜书白话解读
https://www.bilibili.com/video/BV17J411C7zZ/?spm_id_from=333.788.videocard.0
https://www.bilibili.com/video/BV1wx411o7CK?p=3

trie, union find,heap 第二章 数据结构（二）

trie - efficient store and find string set
in dictionary order;
https://www.geeksforgeeks.org/trie-insert-and-search/


台湾大学林轩田机器学习笔记
https://github.com/apachecn/ntu-hsuantienlin-ml

(上海交通大学张志华)机器学习导论

https://www.bilibili.com/video/BV1jt411b76n/?spm_id_from=333.788.videocard.0
same as not much content http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=397

<<<<<<< HEAD
foundations of machine learning book https://cs.nyu.edu/~mohri/mlbook/

=======
>>>>>>> 4ce3a9db7aa3cc1482630adf91fe787828ed5d79
taiwan
https://www.youtube.com/watch?v=9kra9i6jS1g&list=PLk5MIQ__5Xo02mG9liAPl5vpjup7LapFr&index=1

# -*- coding: UTF-8 -*-

import pickle
然后选几样您喜欢的小菜，统统装进【葫芦】里。

food = ["白萝卜", "白菜", "黄瓜", "卷心菜", "海带"]
接下来，只要把食物放进去，封口(dump)，找个地方放着就成了。讲究点的，也会专门在冰箱或者储物柜里留个包场，就像这样：

pickle.dump(food, open("./data/food", "w"))
赶明儿和客人谈得热闹，就可以摆上两三小菜，再来两盅老酒，一杯清茶：

import pickle

food = pickle.load(open("./data/food", "r"))
不过啊，这样做出来的小菜，放哪儿都一样，太平淡了，比洋人的可乐炸鸡还标准：

【./data/food】（in python2）


这样做菜快是快了，却少了点咱传统里，高山流水酬知音那味儿，总觉不够尽心。

因此小店总是按客人的口味，多配几种【盐(salt)】。这便是小店的【绝密拍黄瓜(EncryptedPickle)】。

客人爱吃榴莲口儿的，就记上, salt = “榴莲”

#!/bin/env python2

#encoding=utf-8

from encryptedpickle import encryptedpickle

salt = '\0' * 26 + '榴莲'

passphrases = {

0: salt

}

food = ["白萝卜", "白菜", "黄瓜", "卷心菜", "海带"]

encoder = encryptedpickle.EncryptedPickle(

signature_passphrases=passphrases,

encryption_passphrases=passphrases

)

special_pickle = encoder.seal(food)

with open('./data/food_with_salt', 'w') as f:

f.write(special_pickle)
别的客人要想打开看看坛子里装的什么内容，可就没那么容易了。

【./data/food_with_salt】（in python2）

EPAQAAAAABAAAAPPkdEWPeLgAdqqGIV3CbNy-wJqTvVX_vw-fvcdTJt0lnHUtAG8K3yKyNwoGK9QDFN1cLj4Ba7eXJqRKEiamAB2uQdUsgvKHgICQYxdT_7cJXLb3M9wj76b6E0-gPBlD-GDu7iOaZH2nWMGJJn_we3QC9Lnmlfek-GbrAJYvcDSDLxtdo9CXtPkAc9Ah0dHehFapOk2YMXYCPxaU5kGX1S53ekqMoNAcRuQ7_i42ccyONoyeyvr_s8MwhrZugUU3a2Z0gArhHEyH3hQBUAMtSwg
这salt的内容，可是咱们之间的秘密。

来，尝尝这为您私人订制的小菜：

encoder.unseal(special_pickle)

https://www.acwing.com/file_system/file/content/whole/index/content/1386881/


https://www.youtube.com/watch?v=0ttRHJUHZog&list=PLXVfgk9fNX2L9tQhO-Tqk58TzC6mTJ7OV&index=7
https://github.com/yiaktan/NLP-Stock-Prediction/blob/master/Data%20Collection%20%26%20PreProcessing.ipynb

https://github.com/decentralion/RoboBuffett not working
machine learning stock analysis edgar github

https://www.csie.ntu.edu.tw/~htlin/course/ml20fall/
Hsuan-Tien Lin

probability to the rescue - hoeffding inequality!!!
https://www.youtube.com/watch?v=MgAihqFPkZc&list=PLXVfgk9fNX2L9tQhO-Tqk58TzC6mTJ7OV&index=6

P[|m-n|>e] <= 2 exp (-2*e^2*N)
N is sample size; m is real unknown out-of-sample mean; n is the in-sample nu;
does not depend on mu, no need to know mu!
probably approximately correct (PAC)

https://www.youtube.com/watch?v=0ttRHJUHZog&list=PLXVfgk9fNX2L9tQhO-Tqk58TzC6mTJ7OV&index=7

iid=independent and identically distributed

Textbook: Learning from Data, by Yaser Abu-Mostafa, Malik Magdon-Ismail and Hsuan-Tien Lin
has Hoeffding inequality

DSA:
Textbook: Data Structures and Algorithms in C++, 2nd Edition by Goodrich, Tamassia and Mount

pattern=function=model?

Russell and Norvig. Artificial Intelligence: A Modern Approach. A comprehensive reference for all the AI topics that we will cover.
Koller and Friedman. Probabilistic Graphical Models. Covers factor graphs and Bayesian networks (this is the textbook for CS228).
Sutton and Barto. Reinforcement Learning: An Introduction. Covers Markov decision processes and reinforcement learning. Available free online.
Hastie, Tibshirani, and Friedman. The elements of statistical learning. Covers machine learning. Available free online.
Tsang. Foundations of constraint satisfaction. Covers constraint satisfaction problems. Available free online.
https://stanford-cs221.github.io/autumn2020/

Statistical Learning Theory
https://github.com/percyliang/cs229t/blob/master/lectures/notes.pdf


ML for Edgar:
https://github.com/yiaktan/NLP-Stock-Prediction/blob/master/Data%20Collection%20%26%20PreProcessing.ipynb

python3 -m venv myenv
source myenv/bin/activate
#jupyter notebook test.ipynb will start safari
jupyter notebook Data\ Collection\ \&\ PreProcessing.ipynb





利用STL::allocator分配特定类型的数组
小小蒟蒻的头像小小蒟蒻
16小时前
#include <memory>
#include <iostream>
#include <string>
using namespace std;
const int MAX_LEN = 10;

int main()
{
    // 利用stl的allocator构造int数组
    allocator<int> type_int;
    int* a = type_int.allocate(MAX_LEN);
    for (int i = 0; i < MAX_LEN; i++)
    {
        type_int.construct(a + i, i);
        cout << a[i] << " ";
    }
    cout << endl;

    for (int i = 0; i < MAX_LEN; i++)
    {
        type_int.destroy(a + i);
    }
    type_int.deallocate(a, MAX_LEN);

    return 0;
}




美团机试题 求助
来日可期_7的头像来日可期_7
12小时前
我们称一个长度为n的序列为正则序列，当且仅当该序列是一个由1~n组成的排列，即该序列由n个正整数组成，取值在[1,n]范围，且不存在重复的数，同时正则序列不要求排序。
有一天小团得到了一个长度为n的任意序列，他需要在有限次操作内，将这个序列变成一个正则序列，每次操作他可以任选序列中的一个数字，并将该数字加一或者减一。请问他最少用多少次操作可以把这个序列变成正则序列。

输入描述：
输入第一行仅包含一个正整数n,表示任意序列的长度。(1<=n<= 20000)
输入第二行包含n个整数，空格隔开，表示给出的序列，每个数的绝对值都小于10000。



trinity 2015 taiwan
AI, data mining, stats
theory : hoeffding, multi-bin hoeffding, vc
linear models: PLA/pocket, linear regression, logistic regression
tools: feature transform,regularization, validation
future: transform, regularization,less label
KDDCup2011
https://www.youtube.com/watch?v=jIpwy-mPvIA&list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2&index=65
matrix factorization, restricted boltzmann machine, k NN, prob latent semantic analsys
linear regression, NNet, GBDT
2012 linear blending of models without overfitting
random forest, GBDT variants, designing features
construct features w/ domain knowledge
ICDM 2006 -decision tree, k-means,SVM, apriori - for frequent iemset mining
EM - alternating optimation
pagerank - link-analysis, matrix factorization
adaboost
knn
naive bayes
c&rt - data mining
missing linreg, logreg,random forst, nnet, gbdt
machine learning jungle
1126 is a lunck number?

https://www.bilibili.com/video/BV1aE411o7qd?p=130
机器学习-白板推导系列-合集
共23个系列, 130个视频
pla- perceptron linear algorithm

caltech cs156 yaser on ML: 2012
baysian - just watch the last video - reverse the order!
google earth, brain
entropy = VC dimension, hypothesis testing
stem=reductionism=god
multimeter + co detector

airplane wheels
trinity - data snooping/honesty, razor, sampling bias, ; newton 3;
pattern, data

https://clist.by/

https://blog.csdn.net/dingyahui123/article/details/78446329

浅谈人工智能：现状、任务、构架与统一

原创 2017-11-02 朱松纯

目录

引言

第一节 现状：正视现实
第二节 未来：一只乌鸦给我们的启示
第三节 历史：从“春秋五霸”到“战国六雄”
第四节 统一：“小数据、大任务”范式与认知构架
第五节 学科一：计算视觉 — 从“深”到“暗”
第六节 学科二：认知推理 — 走进内心世界
第七节 学科三：语言通讯 — 沟通的认知基础
第八节 学科四：博弈伦理 — 获取、共享人类的价值观
第九节 学科五：机器人学 — 构建大任务平台
第十节 学科六：机器学习 — 学习的终极极限与“停机问题”
第十一节 总结： 智能科学 — 牛顿与达尔文的统一

http://www.stat.ucla.edu/~sczhu/index.html

google interview - 2455 19
275 2457

AI
cs50 https://cs50.harvard.edu/ai/2020/
AI Book-
https://drive.google.com/file/d/1Ipqb9gjCP0D9j5aqRhg80uIQg5knFbvi/view?usp=sharing
```



[\
](https://github.com/Jack-Cherish/Deep-Learning)
